# Message Queue System - Burst Detection & Smart Combining

## Problem Statement

When users send multiple messages rapidly (e.g., "hello", "my light is broken", "can you help?"), the bot should **combine them into ONE context** and send **ONE comprehensive AI response** instead of processing each message independently.

### Example Scenario:
1. User sends "hello"
2. User sends "my light is broken" (2 seconds later)
3. User sends "can you help?" (1 second later)

**Bad Approach** âŒ: Three separate AI calls â†’ Three responses  
**Good Approach** âœ…: One combined AI call â†’ One comprehensive response

## Root Cause

Previously, each message was processed independently without detecting message bursts from the same user. This led to:
- Multiple AI responses for related messages
- Higher OpenAI API costs
- Fragmented conversation context
- Poor user experience

## Solution: Message Queue with Burst Detection

### Implementation Overview

Added a **message queue system** that:
1. **Collects messages** from the same user in a time window
2. **Waits for burst to complete** (2-second timeout)
3. **Combines all messages** into one context
4. **Sends ONE AI response** for the entire burst

### Key Components

#### 1. User Message Queue Map
```javascript
const userMessageQueues = new Map();
// userId -> { 
//   messages: [{ text, id, type, timestamp }],
//   timer: timeoutId,
//   processing: false 
// }
```

#### 2. Queue Configuration
```javascript
const QUEUE_WAIT_TIME = 2000; // 2 seconds - wait for burst to complete
```

#### 3. Core Functions
- `queueUserMessage(userId, text, messageId, type, object)` - Add message to queue
- `processUserQueue(userId)` - Combine & process all queued messages

### Processing Flow

```
Message 1 arrives: "hello"
   â†“
âœ… Deduplication check passed
   â†“
ğŸ“¥ Add to queue for user X
   â†“
â±ï¸  Start 2-second timer
   â†“
Message 2 arrives: "my light broke" (1 second later)
   â†“
âœ… Deduplication check passed
   â†“
ğŸ“¥ Add to same queue
   â†“
â±ï¸  RESET timer (2 seconds from now)
   â†“
Message 3 arrives: "help me" (0.5 seconds later)
   â†“
âœ… Deduplication check passed
   â†“
ğŸ“¥ Add to same queue
   â†“
â±ï¸  RESET timer (2 seconds from now)
   â†“
... 2 seconds pass with no new messages ...
   â†“
ğŸš€ PROCESS QUEUE:
   - Combine: "hello\n\nmy light broke\n\nhelp me"
   - Send to OpenAI Assistant
   - Get ONE comprehensive response
   - Send back to user
   â†“
ğŸ—‘ï¸  Clean up queue for user X
```

### Code Changes

#### Before:
```javascript
// Each message processed independently
case "text": {
  const aiReply = await openaiService.getAIResponse(userRequest, number);
  whatsappService.sendWhatsappResponse(payload);
  // Result: 3 separate AI calls for 3 messages
}
```

#### After:
```javascript
// Messages queued and combined
case "text": {
  queueUserMessage(number, userRequest, messageId, messageType, messageObject);
  // Timer starts/resets
  // After 2s of silence â†’ processUserQueue()
  //   - Combines all queued messages
  //   - ONE AI call with full context
  //   - ONE comprehensive response
}
```

## Benefits

### âœ… User Experience
- **No duplicate responses** when user sends multiple messages
- Bot appears more intelligent and controlled
- Reduces user confusion

### âœ… Cost Optimization
- **Saves OpenAI API costs** by not processing duplicate requests
- **Reduces WhatsApp API calls** by not sending duplicate responses

### âœ… Server Performance
- Prevents **concurrent processing** for same user
- Reduces **database load** (fewer thread operations)
- Prevents **race conditions** in thread management

## Enhanced Logging

The queue system includes detailed console logging:

```
ğŸ”” [2025-11-06T...] NEW WEBHOOK RECEIVED
   Message ID: wamid.XXX
   From: 529991234567
   Text: "hello"
   Active queues: 0

ï¿½ QUEUED - Message added to queue for 529991234567 (queue size: 1)
â±ï¸  Timer set - Will process queue in 2000ms if no new messages arrive
ğŸ“¤ Webhook response sent to WhatsApp

--- User sends second message 1 second later ---

ğŸ”” [2025-11-06T...] NEW WEBHOOK RECEIVED
   Message ID: wamid.YYY
   From: 529991234567
   Text: "my light is broken"
   Active queues: 1

ğŸ“¥ QUEUED - Message added to queue for 529991234567 (queue size: 2)
â±ï¸  Timer set - Will process queue in 2000ms if no new messages arrive
ğŸ“¤ Webhook response sent to WhatsApp

--- 2 seconds pass with no new messages ---

ğŸš€ PROCESSING QUEUE for 529991234567 - 2 message(s)
ğŸ“ Combined message (27 chars):
   "hello

my light is broken"
ğŸ¤– Calling OpenAI Assistant with combined context...
ğŸ¤– OpenAI response received in 4.52s (length: 245 chars)
âœ… Single AI response sent to 529991234567 for 2 message(s)
ğŸ”“ Queue processing finished for 529991234567
```

## Testing Scenarios

### âœ… Test 1: Message Burst (Main Feature)
**Steps:**
1. Send "hello" to bot
2. **Immediately** send "my light is broken" (within 2 seconds)
3. **Immediately** send "can you help?" (within 2 seconds)
4. Wait for response

**Expected Result:**
- âœ… Only **ONE** comprehensive AI response received
- âœ… Response addresses all three messages contextually
- âœ… Console shows queue building up, then processing all together

### âœ… Test 2: Slow Messages (Normal Conversation)
**Steps:**
1. Send "hello" to bot
2. **Wait 5 seconds** (longer than QUEUE_WAIT_TIME)
3. Send "how are you?"

**Expected Result:**
- âœ… **TWO** separate responses (queue processed after first timeout)
- âœ… Each message processed independently

### âœ… Test 3: Error Recovery
**Steps:**
1. Send message that triggers OpenAI error
2. Send another message immediately

**Expected Result:**
- âœ… Error message sent to user
- âœ… Queue cleaned up properly
- âœ… Second message creates new queue and processes normally

## Edge Cases Handled

### ğŸ›¡ï¸ Error Recovery
User lock is **always released** in try/catch blocks:
```javascript
try {
  // Process message
  finishProcessingUser(number);
} catch (err) {
  finishProcessingUser(number); // âœ… Unlock on error
}
```

### ğŸ›¡ï¸ All Message Types
Lock/unlock pattern applied to:
- âœ… Text messages
- âœ… Image messages (with Cloudinary upload)
- âœ… Location messages (with geocoding)

### ğŸ›¡ï¸ Memory Management
`processingUsers` Map is automatically cleaned when processing finishes (no memory leak).

## Monitoring

### Key Metrics to Track
1. **Processing users count**: `processingUsers.size`
2. **"USER BUSY" occurrences**: Count of ignored messages
3. **Average processing time**: Time between lock/unlock
4. **OpenAI API calls reduction**: Compare before/after metrics

### Dashboard Query (Future)
```javascript
GET /api/v2/stats
{
  "processedMessages": 150,
  "ignoredDuplicates": 45,
  "activeProcessingUsers": 3,
  "avgProcessingTime": "5.2s",
  "costSavings": "$0.15"
}
```

## Related Documentation
- [DUPLICATE_MESSAGE_PREVENTION.md](./DUPLICATE_MESSAGE_PREVENTION.md) - WhatsApp webhook deduplication
- [THREAD_RUN_CONFLICT_FIX.md](./THREAD_RUN_CONFLICT_FIX.md) - OpenAI thread concurrency
- [CODE_REVIEW_DUPLICATE_PREVENTION.md](./CODE_REVIEW_DUPLICATE_PREVENTION.md) - Full code review

## Deployment Checklist

- [x] Code implemented with lock/unlock pattern
- [x] Error handling with unlock on failure
- [x] Applied to all message types (text, image, location)
- [x] Enhanced logging for debugging
- [x] No memory leaks (Map cleanup)
- [ ] Test with production WhatsApp (rapid messages)
- [ ] Monitor OpenAI cost reduction
- [ ] Track "USER BUSY" occurrences in logs

---

**Fix Date**: November 6, 2025  
**Impact**: Critical - Prevents duplicate AI responses when users spam messages  
**Status**: âœ… Deployed and Ready for Testing
